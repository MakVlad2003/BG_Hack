{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "# **2/3 малышей**\n",
    "\n",
    "1) Носова Ирина Вадимовна (4 курс МФТИ, ФБМФ)\n",
    "\n",
    "2) Терещук Вера Юрьевна (4 курс МФТИ, ФБМФ)\n",
    "\n",
    "3) Болев Михаил Алексеевич (4 курс МФТИ, ФБМФ)\n",
    "\n",
    "4) Макаров Владислав Денисович (4 курс МФТИ, ФБМФ)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание задачи\n",
    "\n",
    "**Цель:** Проверить пары иммунных репертуаров на наличие ответа на заданный патоген. Для этого необходимо сопоставить последовательности CDR3-региона Т-клеточного рецептора с известными последовательностями из базы данных. При этом следует учитывать, что само наличие последовательности в репертуаре не гарантирует наличие ответа.\n",
    "\n",
    "## Входные данные\n",
    "- **База данных:** vdjdb.\n",
    "- **Таблицы:** Данные о клонотипах.\n",
    "\n",
    "## Ожидаемые результаты\n",
    "Участникам требуется:\n",
    "1. Разработать подход, позволяющий:\n",
    "   - Определить наличие ответа на патоген.\n",
    "   - Оценить степень уверенности в том, что найденный ответ не случаен.\n",
    "2. Продемонстрировать работу метода на предоставленных таблицах с неизвестным статусом.\n",
    "\n",
    "**Критерии оценки:**\n",
    "- Успешное определение статусов таблиц.\n",
    "- Подробный отчет о методах.\n",
    "- Качественная интерпретация результатов.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт необходимых библиотек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9qp2CNpl7mZQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Базовые библиотеки\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorch и модель ESM\n",
    "import torch\n",
    "from transformers import EsmTokenizer, AutoModel\n",
    "\n",
    "# Модели и метрики из scikit-learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# CatBoost\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Использование эмбеддингов и классификации для анализа CDR3-последовательностей**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Этап 1. Инициализация модели и токенизатора**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Взяли довольно популярную модель предобученную на большом количестве данных аминокислотных последовательностей. Предобучалась на задаче MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344,
     "referenced_widgets": [
      "67c1752534ee4687bcfddcb90a9465fc",
      "afadf2d4d8d44478af62bbf6b4370914",
      "cd99a385ef074e449cd7ad3764d8c8af",
      "bd2cf681950b424cb6bfa4dbd0107eee",
      "1f679866ee5443b0954424b638e95d63",
      "18a01f0307c6433abd0d561b24ace0b0",
      "ff0caec096494fb29480ce137e344f6d",
      "b9bdff9f0c154a019f361645a0673b62",
      "9a38a5d92c9c451cb6a81b5896cda78e",
      "74b52564475945ffa2ec5b2d29bf28de",
      "a1096f1abbd74a1bbc0da6fe5143c7c0",
      "b12e341c22e540ecba288e53c0218ace",
      "dd6169480a54439ba9898aeea1ac8922",
      "818a47a0d33d42469fe377978257248b",
      "0be563d2583142748ade22311164a869",
      "942def5623e0460e8134753b1fb030e6",
      "10c0519814b94a5b840a5e4b125cbc17",
      "b5e40f089350485db05062cd6103cb17",
      "d5d5011778504c36a9c7a4e586205054",
      "37969d8492984460a282273ce731f508",
      "bbed4e15f3e94ba3a1f7d062ad0252c2",
      "ae5a37893bf6433ebec791bf74e316b5",
      "7ed74475055f47098d13494bf910d0cd",
      "46b146dd51b245018bb17cefe4d102bc",
      "5474fff1462d454ea7dfbaea126337e0",
      "c2bc5fe2bfbf44fdacb7b310125c5acf",
      "7b84cac680ad45f497afc14172fd87b2",
      "027265b6ea134556887ce867c96c8d9b",
      "03420eb247134e6f96921674cd45dd2c",
      "941f1c60a1334b6cb6287f523bbe2046",
      "d2433eaff7d742e585573810db1d013f",
      "dc7a1c4aba6b4418a23d69b11af7d232",
      "4392841471094c2fb9b807cf96bdff92",
      "4ec51e7a3d8f451487c9e2ccded89530",
      "02ea2f3351054160a766266fd9691c8c",
      "c93797bc79de45558d771db271efcb5d",
      "ff77d92b91a4443fb1e0064e8e980d13",
      "3829742b2c344af7832478ab6ffe62dc",
      "23ae997a24004fc69e042a9d84e3cd4e",
      "866d0d4ca3f44e87849e15ccd1556a92",
      "f6f8dfc9948c480bba525935c4d12aea",
      "ad39ba7ec9684bcaa12f3b5da31e41c6",
      "8fd5c184eb334de9bb48adac566830e5",
      "febb60630f0047749d295b5b8a65ac76",
      "9bf6220165994be0a635f47ca6b43484",
      "75c65a88118a4137b5bf6b08ceafc69e",
      "566d222b2d28499691276368a143c927",
      "27f723deab1c48f983897c87c0fdc41b",
      "1c602f9b972545d2b4b5506aebd7ec44",
      "67001b88ad634183b3e281283b42593d",
      "22f21be4c4704e43b1e4f611ac3d1371",
      "37bedbb06cae4703ae887bd3685a0f9c",
      "8e0f48e1b7a44b288d1486caa1a06eb9",
      "60149848b34241b391a977d2b4398fad",
      "7e50ef56409847289dffd9edb9c5a9f6"
     ]
    },
    "id": "sq7OPLGd7ymO",
    "outputId": "9c9c4de4-fbb1-496d-c7dc-8e0deb7bc062",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = EsmTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "model = AutoModel.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DagApZYP8unS",
    "outputId": "1e751ba8-4d73-4d94-c06a-9e22c8bcac6d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Комментарий:**\n",
    "\n",
    "Мы используем предобученную модель ESM2 от Facebook, которая предназначена для анализа последовательностей белков. Токенизатор преобразует аминокислотные последовательности в числовой вид, а модель извлекает эмбеддинги.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Этап 2. Упрощение модели**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уберем верхний слой, т.к. он отвечает за классификацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ngm1gz9J78z7",
    "outputId": "655244a8-5f5a-4a78-b65d-c561299e1676",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.contact_head = None\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CSail-nr9D5q",
    "outputId": "7a3694ee-be82-4d07-c099-6b87c506aea3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.pooler = None\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перенос на GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Этап 3. Функция для получения эмбеддингов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LqbVazzX9hDX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_embeddings(sequence):\n",
    "    # Токенизация и перенос на GPU\n",
    "    inputs = tokenizer(sequence, return_tensors=\"pt\", add_special_tokens=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        inputs.to('cuda') # Перенос входных данных на GPU\n",
    "        outputs = model(**inputs) # Прогон через модель\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1) # Среднее значение по всем токенам\n",
    "    return embeddings.squeeze().cpu().numpy() # Возвращаем эмбеддинги в формате numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Этап 4. Пример извлечения эмбеддингов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Wp6pu1t-CYm",
    "outputId": "6008a7f1-ffbb-41f6-9558-609924efe85b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Пример последовательностей\n",
    "sequences = [\"MKTFFVAGLFVMLAALSG\", \"VLGFLVLTLTGAAGQVLG\"]  \n",
    "embeddings = np.array([get_embeddings(seq) for seq in sequences])\n",
    "print(\"Размер эмбеддингов:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Этап 5. Загрузка данных из базы vdjdb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QJ6HdLkd-Krw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"vdjdb.slim.txt\", sep='\\t')\n",
    "df_homo = df[df['species'] == 'HomoSapiens'][['cdr3', 'antigen.species']]\n",
    "df_homo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Этап 6. Извлечение эмбеддингов для всех последовательностей**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E0fEU6NY_aPF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = df_homo['antigen.species']\n",
    "data = df_homo.drop('antigen.species', axis=1)\n",
    "\n",
    "X_data = []\n",
    "for i in tqdm(range(75)):\n",
    "    X_data.append(get_embeddings(data['cdr3'].tolist()[i*1000:(i+1)*1000]))\n",
    "\n",
    "X_data = np.concatenate(X_data, axis=0)\n",
    "X_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Этап 7. Предобработка данных для обучения**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZ7SpQuTjwDi",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Замена редких классов на категорию \"others\"\n",
    "class_counts = labels.value_counts()\n",
    "classes_to_replace = class_counts[class_counts < 200].index\n",
    "labels_new = labels.where(labels.isin(classes_to_replace) == False, 'others')\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, labels_new, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hsKAme35-_KZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Этап 8. Обучение модели CatBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qFxq2jqbKt30",
    "outputId": "ec5a1ef4-a012-44aa-cab9-93f3486a7cce",
    "tags": []
   },
   "outputs": [],
   "source": [
    "catboost = CatBoostClassifier(task_type=\"GPU\", iterations=2000, loss_function=\"MultiClass\")\n",
    "catboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Этап 9. Оценка качества модели**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89JmwQOYV0Tq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_proba= catboost.predict_proba(X_test)\n",
    "preds = catboost.predict(X_test)\n",
    "\n",
    "roc_auc = roc_auc_score(y_true=y_test, y_score=preds_proba, multi_class='ovr')\n",
    "print(f\"ROC-AUC: {roc_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Этап 10. Альтернативные модели**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Обучение Logistic Regression\n",
    "logreg = LogisticRegression(multi_class=\"ovr\", max_iter=2000, random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Обучение Random Forest\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Предсказания вероятностей для Logistic Regression\n",
    "preds_proba_logreg = logreg.predict_proba(X_test)\n",
    "preds_logreg = logreg.predict(X_test)\n",
    "\n",
    "# Расчет ROC-AUC для Logistic Regression\n",
    "roc_auc_logreg = roc_auc_score(y_true=y_test, y_score=preds_proba_logreg, multi_class='ovr')\n",
    "print(f\"ROC-AUC (Logistic Regression): {roc_auc_logreg:.3f}\")\n",
    "\n",
    "# Предсказания вероятностей для Random Forest\n",
    "preds_proba_rf = random_forest.predict_proba(X_test)\n",
    "preds_rf = random_forest.predict(X_test)\n",
    "\n",
    "# Расчет ROC-AUC для Random Forest\n",
    "roc_auc_rf = roc_auc_score(y_true=y_test, y_score=preds_proba_rf, multi_class='ovr')\n",
    "print(f\"ROC-AUC (Random Forest): {roc_auc_rf:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** Метрики хуже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LnFQHHE-qWF8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Этап 10. Тюнинг гиперпараметров**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем optuna для подбора гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L455wqgBYqZ8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"iterations\": 2000,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 10),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1, 500, log=True),\n",
    "    }\n",
    "\n",
    "    model = CatBoostClassifier(task_type=\"GPU\", loss_function=\"MultiClass\", silent=True, **params)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict_proba(X_val)\n",
    "    roc_auc = roc_auc_score(y_true=y_val, y_score=predictions, multi_class='ovr')\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zqs6-DP0aHGc",
    "outputId": "07bb3b09-debb-4b19-9680-9a90209f3ff5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wUrggeiprrrT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Этап 12. Обучаем модель с лучшими гиперпараметрами**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, labels_new, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {'learning_rate': 0.03899128323378634,\n",
    " 'depth': 10,\n",
    " 'l2_leaf_reg': 2.4095622667503007}\n",
    "catboost = CatBoostClassifier(task_type=\"GPU\", iterations=2000, loss_function=\"MultiClass\", **best_params)\n",
    "catboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем ROC-AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_proba= catboost.predict_proba(X_test)\n",
    "preds = catboost.predict(X_test)\n",
    "roc_auc_score(y_true=y_test, y_score=preds_proba, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Этап 13. Прогноз на образцах**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!unzip for_task.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем датафреймы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_tsv_files_from_folder(folder_path):\n",
    "    \n",
    "    dataframes = []\n",
    "    file_names = []\n",
    "    \n",
    "    # Проходимся по всем файлам в папке\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.tsv'):  # Проверяем, что файл имеет расширение .tsv\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                # Читаем файл и добавляем в список\n",
    "                df = pd.read_csv(file_path, sep='\\t')\n",
    "                dataframes.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Не удалось прочитать файл {file_name}: {e}\")\n",
    "        file_names.append(file_name)\n",
    "    \n",
    "    return dataframes, file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder_path = \"for_task\"\n",
    "dataframes, file_names = read_tsv_files_from_folder(folder_path)\n",
    "\n",
    "print(f\"Количество датафреймов: {len(dataframes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставим столбец только с аминокислотными последовательностями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframes_new = []\n",
    "for df in dataframes:\n",
    "    list_columns = list(df.columns)\n",
    "    X_columns=[]\n",
    "    for column in list_columns:\n",
    "        if 'cdr3aa' in column.lower() or 'cdr3.amino' in column.lower():\n",
    "            X_columns.append(column)\n",
    "    df_new = df[X_columns]\n",
    "    dataframes_new.append(df_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим эмбеддинги для модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_all = []\n",
    "for dataframe in tqdm(dataframes_new):\n",
    "    X_data = []\n",
    "    list_column = list(dataframe.columns)\n",
    "    for i in range(0, len(dataframe), 20000):\n",
    "        X_data.append(get_embeddings(dataframe[str(*list_column)].tolist()[i:i+20000]))\n",
    "    X_data = np.concatenate(X_data, axis=0)\n",
    "    X_all.append(X_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим прогнозы на всех образцах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_all = []\n",
    "for X in tqdm(X_all):\n",
    "    preds = catboost.predict(X)\n",
    "    preds_all.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answers = []\n",
    "for i, pred in enumerate(preds_all):\n",
    "    answers.append(pred.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим итоговую таблицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "\n",
    "for i, answer in enumerate(answers):\n",
    "\n",
    "    unique_answer, num_unique = np.unique(answer, return_counts=True)\n",
    "    \n",
    "    d[file_names[i]] = {\"answers\": unique_answer,\n",
    "                       \"unique\": num_unique}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_for_df = []\n",
    "\n",
    "for sample_name, values in d.items():\n",
    "    \n",
    "    answers = values[\"answers\"]\n",
    "    unique_values = values[\"unique\"]\n",
    "     \n",
    "    sorted_indices = unique_values.argsort()[::-1]  \n",
    "    sorted_answers = answers[sorted_indices]     \n",
    "     \n",
    "    row = {\"Sample\": sample_name}\n",
    "    row.update({f\"Answer_{i+1}\": answer for i, answer in enumerate(sorted_answers)})\n",
    "    data_for_df.append(row)\n",
    "\n",
    "df_final = pd.DataFrame(data_for_df)\n",
    "\n",
    "df_final = df_final.fillna(value=pd.NA)\n",
    "\n",
    "cols = [\"Sample\"] + [col for col in df_final.columns if col != \"Sample\"]\n",
    "df_final = df_final[cols]\n",
    "\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Объяснение:** В таблице представлены все патогены найденные в образцах. Они отсортированы в порядке встречаемости в образце, то есть Answer_1 самый часто встречающийся патоген в образце. Как мы видим, почти у всех есть антитела к CMV, InfluenzaA, SARS-CoV-2, поэтому можно сделать фильтрацию(убрать первые три ответа)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_final.to_csv('answers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем фильтрацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answers = []\n",
    "for i, pred in enumerate(preds_all):\n",
    "    answers.append(pred.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "\n",
    "for i, answer in enumerate(answers):\n",
    "\n",
    "    unique_answer, num_unique = np.unique(answer, return_counts=True)\n",
    "    indices_of_top = np.argsort(num_unique)[:-3]\n",
    "    \n",
    "    d[file_names[i]] = {\"answers\": unique_answer[indices_of_top],\n",
    "                       \"unique\": num_unique[indices_of_top]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_for_df = []\n",
    "\n",
    "for sample_name, values in d.items():\n",
    "\n",
    "    answers = values[\"answers\"]\n",
    "    unique_values = values[\"unique\"]\n",
    "    \n",
    "    sorted_indices = unique_values.argsort()[::-1]  \n",
    "    sorted_answers = answers[sorted_indices]        \n",
    "    \n",
    "    \n",
    "    row = {\"Sample\": sample_name}\n",
    "    row.update({f\"Answer_{i+1}\": answer for i, answer in enumerate(sorted_answers)})\n",
    "    data_for_df.append(row)\n",
    "\n",
    "\n",
    "df_final = pd.DataFrame(data_for_df)\n",
    "\n",
    "df_final = df_final.fillna(value=pd.NA)\n",
    "\n",
    "cols = [\"Sample\"] + [col for col in df_final.columns if col != \"Sample\"]\n",
    "df_final = df_final[cols]\n",
    "\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь представлена отфильтрованная таблица"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_final.to_csv('filtered_answers.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
