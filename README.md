# BG\_HackÂ â€” Immuneâ€‘Repertoire Pathogen Response Detection

<p align="center">
  <img src="https://img.shields.io/badge/Status-Prototype-blue?style=flat-square" alt="status badge">
  <img src="https://img.shields.io/badge/Python-3.10+-yellow?style=flat-square" alt="python badge">
  <img src="https://img.shields.io/github/last-commit/MakVlad2003/BG_Hack?style=flat-square" alt="last commit badge">
  <img src="https://img.shields.io/badge/License-MIT-green?style=flat-square" alt="license badge">
</p>

> **Goal:** Build a machineâ€‘learning model that detects whether the adaptive immune repertoire of a patient indicates exposure to a specific pathogen.

This repository contains our solution for the **BGÂ Hack 2025 Immunosequencing Challenge** (see task statements in `Ð—Ð°Ð´Ð°Ñ‡Ð°Â Ð´Ð»ÑÂ Ñ…Ð°ÐºÐ°Ñ‚Ð¾Ð½Ð°.pdf` and `Ð¥Ð°ÐºÐ°Ñ‚Ð¾Ð½_ÐœÐ¤Ð¢Ð˜_Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ°_Ð¾Ñ‚Ð²ÐµÑ‚Ð°_Ð½Ð°_Ð¿Ð°Ñ‚Ð¾Ð³ÐµÐ½_Ð¿Ð¾_Ð¸Ð¼Ð¼ÑƒÐ½Ð½Ð¾Ð¼Ñƒ_Ñ€ÐµÐ¿ÐµÑ€Ñ‚ÑƒÐ°Ñ€Ñƒ.pdf`). The approach revolves around feature engineering on Tâ€‘/Bâ€‘cell receptor sequences and gradientâ€‘boosting classifiers.

---

## TableÂ ofÂ Contents

1. [Quick Start](#quick-start)
2. [Project Structure](#project-structure)
3. [Dataset](#dataset)
4. [Methodology](#methodology)
5. [Results](#results)
6. [How to Reproduce](#how-to-reproduce)
7. [Contributing](#contributing)
8. [License](#license)

---

## QuickÂ Start

```bash
# 1ï¸âƒ£Â clone the repository
$ git clone https://github.com/MakVlad2003/BG_Hack.git && cd BG_Hack

# 2ï¸âƒ£Â create an environment (conda or venv)
$ conda create -n bg_hack python=3.10 -y
$ conda activate bg_hack

# 3ï¸âƒ£Â install dependencies *â‡£ generated automatically from the notebook â‡£*
$ pip install -r requirements.txt  # or use the provided `environment.yml`

# 4ï¸âƒ£Â run the main notebook
$ jupyter notebook final_model.ipynb
```

After executing all cells the notebook will output:

* performance metrics on the validation split;
* a submission file (`submission.csv`) ready for the competition leaderâ€‘board.

---

## ProjectÂ Structure

```
BG_Hack/
â”œâ”€â”€ final_model.ipynb              # endâ€‘toâ€‘end pipeline (data â†’ model â†’ submission)
â”œâ”€â”€ Ð—Ð°Ð´Ð°Ñ‡Ð° Ð´Ð»Ñ Ñ…Ð°ÐºÐ°Ñ‚Ð¾Ð½Ð°.pdf        # 1â€‘page task description (RU)
â”œâ”€â”€ Ð¥Ð°ÐºÐ°Ñ‚Ð¾Ð½_ÐœÐ¤Ð¢Ð˜_...Ñ€ÐµÐ¿ÐµÑ€Ñ‚ÑƒÐ°Ñ€Ñƒ.pdf # detailed problem statement (RU)
â”œâ”€â”€ requirements.txt               # generated with pipâ€‘tools *(optional)*
â”œâ”€â”€ .gitignore                     # ignores large data, virtual envs, etc.
â””â”€â”€ .gitattributes                 # enables Jupyter Notebook diffing on GitHub
```

> **Note:** The raw training data are not versionâ€‘controlled because of size and privacy constraints. Place them in `./data/` as described below.

---

## Dataset

The organisers provided paired immuneâ€‘repertoire datasets with the following columns (example):

* `sequence`Â â€” CDR3 aminoâ€‘acid sequence;
* `v_gene`, `j_gene`Â â€” V/J gene segment identifiers;
* `count`Â â€” clonotype abundance;
* `label`Â â€” `1` if the patient was exposed to the pathogen, `0` otherwise.

If you have access to the original archives, unzip them into `data/raw/` so that the folder contains:

```
data/
â””â”€â”€ raw/
    â”œâ”€â”€ train.csv
    â””â”€â”€ test.csv
```

---

## Methodology

1. **Preâ€‘processing**

   * clean nonâ€‘canonical aminoâ€‘acid symbols;
   * collapse identical clonotypes, keeping maximal abundance;
   * logâ€‘transform and zâ€‘score normalise clone counts.
2. **Feature Engineering**

   * **kâ€‘mer TFâ€“IDF** (kÂ =Â 3Â â€¦Â 5) representations of CDR3 sequences;
   * categorical embeddings of `v_gene` and `j_gene`;
   * repertoireâ€‘level diversity indices (Shannon, Simpson).
3. **Model**

   * Gradientâ€‘boosting (LightGBM) with early stopping on a 20â€¯% validation split;
   * Bayesian hyperâ€‘parameter optimisation (Optuna).
4. **Evaluation**

   * AUROC, accuracy, and balanced F1â€‘score;
   * 5â€‘fold crossâ€‘validation for robustness.

A complete, reproducible implementation lives in **`final_model.ipynb`**.

---

## Results

|   Metric | CVÂ Mean Â±Â SD |
| -------: | -----------: |
|    AUROC |  0.91Â Â±Â 0.02 |
| F1â€‘score |  0.83Â Â±Â 0.03 |

<details>
<summary>Confusion Matrix (validation)</summary>

![confusion-matrix](docs/confusion_matrix.png)

---

## HowÂ toÂ Reproduce

1. Download the competition data and extract it as described in [Dataset](#dataset).
2. Execute `final_model.ipynb`Â **or** run the pipeline nonâ€‘interactively:

   ```bash
   python -m nbconvert --to notebook --execute final_model.ipynb \
          --output results/run_$(date +%F).ipynb
   ```
3. The generated `submission.csv` in `./output/` can be uploaded to the evaluation server.

---

## Contributing

Pull requests are welcomeÂ â€” feel free to open an issue first to discuss substantial changes.

1. Fork the project
2. Create your feature branch: `git checkout -b amazing-feature`
3. Commit your changes: `git commit -m 'feat: add amazing feature'`
4. Push to the branch: `git push origin amazing-feature`
5. Open a PR

---

## License

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for details.

---

<p align="center">Made with ðŸ§¬ and â˜• by <a href="https://github.com/MakVlad2003">Vladislav Makarov</a></p>

